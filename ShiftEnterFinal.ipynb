{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109 Final Project: Breaking Daily Fantasy Basketball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://cdn.playbuzz.com/cdn/b83ad51b-f33e-4b06-879a-8b3f8a509b3e/9f71ec8b-2e9b-4bd4-80ff-ce0f555c5653.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hundreds of Competitions and Millions of Dollars a Day\n",
    "####Overview and Motivation\n",
    "####Related Work\n",
    "####Initial Questions\n",
    "####Exploratory Data Analysis\n",
    "####Final Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load gamelog_data\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from pyquery import PyQuery as pq\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "def season_subset(df, year_season_start, year_season_end = None):\n",
    "    df[\"GAME_DATE\"] = pd.to_datetime(df[\"GAME_DATE\"])\n",
    "    if year_season_end is None:\n",
    "        year_season_end = year_season_start + 1\n",
    "    df_gt = df[df.GAME_DATE > datetime.date(year_season_start,9,1)]\n",
    "    df_lt = df_gt[df_gt.GAME_DATE < datetime.date(year_season_end,9,1)]\n",
    "    return df_lt.sort_values(\"GAME_DATE\") if not df_lt.empty else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post85df = pd.read_csv('./gamelogs/master_post86df.csv')\n",
    "post85df = post85df.drop('VIDEO_AVAILABLE',1)\n",
    "df85_15 = season_subset(post85df,1985,2015)\n",
    "by_player = df85_15.groupby(\"PLAYER_NAME\")\n",
    "MELOadvanceddf = pd.read_csv('./usage_stats/master_advanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df85_15[\"FANTASY_ZSCORE\"] = by_player[\"FANTASY_PTS\"].apply(lambda x: ((x - x.mean())/x.std()))\n",
    "df85_15[\"i_ZSCORE_OVER\"] = df85_15[\"FANTASY_ZSCORE\"].map(lambda x: 1 if x > 1 else 0)\n",
    "df85_15[\"SEASON_MIN\"] = by_player['MIN'].apply(lambda x: x.map(lambda y: x.sum()))\n",
    "df85_15[\"GAMES_PLAYED\"] = by_player[\"PLAYER_NAME\"].apply(lambda x: x.map(lambda y: len(x)))\n",
    "for x in ['FG_PCT', 'FG3_PCT', 'FT_PCT']:\n",
    "    df85_15[x] = df85_15[x].map(lambda y: 0 if np.isnan(y) else y)\n",
    "df85_15[\"WL\"] = [1 if v == \"W\" else 0 for v in df85_15.copy()[\"WL\"]]\n",
    "\n",
    "opp_home = df85_15.MATCHUP.map(lambda x: (x[-3:],0) if \"@\" in x else (x[-3:],1))\n",
    "df85_15[\"OPP\"] = opp_home.map(lambda x: x[0])\n",
    "df85_15[\"i_HOME\"] = opp_home.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add player bio data for age,weight,height\n",
    "player_bios_df = pd.read_csv(\"./player_bios/player_bios.csv\")\n",
    "player_bios_df = player_bios_df.rename(columns = {'PERSON_ID': 'PLAYER_ID', 'DISPLAY_FIRST_LAST': 'PLAYER_NAME'})\n",
    "player_bios_df[\"BIRTHDATE\"] = pd.to_datetime(player_bios_df[\"BIRTHDATE\"])\n",
    "player_bios_df['AGE'] = player_bios_df[\"BIRTHDATE\"].map(lambda x: round((pd.to_datetime('today') - x).days / 365.,2))\n",
    "player_bios_df[\"WEIGHT\"] = player_bios_df[\"WEIGHT\"].astype('str')\n",
    "player_bios_df[\"HEIGHT\"] = player_bios_df[\"HEIGHT\"].astype('str')\n",
    "player_bios_df[\"WEIGHT\"] = player_bios_df[\"WEIGHT\"].map(lambda x:  float(x) if x != 'nan' else 0.)\n",
    "player_bios_df[\"HEIGHT\"] = player_bios_df[\"HEIGHT\"].map(lambda x: (12.*float(x[0]) + float(x[2:])) if x != 'nan' else 0.)\n",
    "\n",
    "by_player = df85_15.groupby(\"PLAYER_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_player_bio(name, col_name):\n",
    "    return float(player_bios_df[player_bios_df.PLAYER_NAME == name][col_name])\n",
    "\n",
    "df85_15[\"AGE\"] = by_player[\"PLAYER_NAME\"].apply(lambda x: x.replace(x.iloc[0],get_player_bio(x.iloc[0],\"AGE\")))\n",
    "df85_15[\"WEIGHT\"] = by_player[\"PLAYER_NAME\"].apply(lambda x: x.replace(x.iloc[0],get_player_bio(x.iloc[0],\"WEIGHT\")))\n",
    "df85_15[\"HEIGHT\"] = by_player[\"PLAYER_NAME\"].apply(lambda x: x.replace(x.iloc[0],get_player_bio(x.iloc[0],\"HEIGHT\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Integrate ELO Rankings\n",
    "elo_df = pd.read_csv(\"./gamelogs/all_elo.csv\")\n",
    "elo_df[\"date_game\"] = pd.to_datetime(elo_df[\"date_game\"])\n",
    "elo_df[\"game_location\"] = elo_df[\"game_location\"].map(lambda x: 1 if x == \"H\" else 0)\n",
    "elo_df = elo_df[elo_df[\"is_playoffs\"] == 0]\n",
    "\n",
    "curr = elo_df.columns.tolist()\n",
    "cols = [curr[i] for i in [5,8,11,13,14,17,19,21]]\n",
    "elo_df = elo_df[cols]\n",
    "elo_df = elo_df.rename(columns={'date_game': 'GAME_DATE',\n",
    "                                'team_id':'TEAM_ABBREVIATION',\n",
    "                                'opp_id':'OPP', \n",
    "                                'game_location': 'i_HOME',\n",
    "                                'elo_i':'ELO',\n",
    "                                'opp_elo_i': 'OPP_ELO',\n",
    "                                'win_equiv': 'EXP_WINS',\n",
    "                                'forecast':'FORECAST'})\n",
    "\n",
    "elo_df['SHIT'] = elo_df['OPP_ELO'].map(lambda x: 1 if x < 1400 else 0)\n",
    "elo_df['OKAY'] = elo_df['OPP_ELO'].map(lambda x: 1 if 1400 <= x < 1600 else 0)\n",
    "elo_df['GOOD'] = elo_df['OPP_ELO'].map(lambda x: 1 if 1600 <= x < 1700 else 0)\n",
    "elo_df['GREAT'] = elo_df['OPP_ELO'].map(lambda x: 1 if 1700 <= x else 0)\n",
    "df85_15 = df85_15.merge(season_subset(elo_df,1985,2015))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rearrange some columns in df85_15\n",
    "curr = df85_15.columns.tolist()\n",
    "cols = curr[:3] + curr[32:37] + curr[3:9] + curr[37:] + curr[9:32]\n",
    "if len(curr) == len(cols):\n",
    "    df85_15 = df85_15[cols]\n",
    "\n",
    "\n",
    "name_pos = player_bios_df[[\"PLAYER_ID\",\"POSITION\",\"PLAYER_NAME\"]]\n",
    "df85_15 = df85_15.merge(name_pos)\n",
    "df85_15[\"POSITION\"] = df85_15.POSITION.map(lambda x: \"Unknown\" if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_season_avg(df,col_list,(date_str1,date_str2)):\n",
    "    date1, date2 = pd.to_datetime(date_str1), pd.to_datetime(date_str2)\n",
    "    mask = lambda x: (date1 <= x) & (x <= date2)\n",
    "    return df[df.GAME_DATE.apply(mask)].groupby([\"PLAYER_NAME\",\"SEASON_ID\"])[col_list].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngames_colname(col_list, ngames):\n",
    "    return map(lambda x: str(ngames) + 'D_' + x, col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_ngames(df,ngames,game_date,col_list):\n",
    "    ngames_df = df[df.GAME_DATE < game_date].nlargest(ngames, \"GAME_DATE\")\n",
    "    ngames_col_list = ngames_colname(col_list,ngames)\n",
    "    num_cols = len(ngames_col_list)\n",
    "    date_player_tuples = [(\"GAME_DATE\",game_date)]#,(\"PLAYER_NAME\",df.PLAYER_NAME.iloc[0])]\n",
    "    if ngames_df.empty:\n",
    "        return dict(date_player_tuples + zip(ngames_col_list,np.array(0).repeat(num_cols)))\n",
    "    else:\n",
    "        return dict(date_player_tuples + zip(ngames_col_list,ngames_df[col_list].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_ngame_avg(df,col_list,game_date_str,ngames):\n",
    "    game_date = pd.to_datetime(game_date_str)\n",
    "    season_id = df[df.GAME_DATE == game_date][\"SEASON_ID\"].iloc[0]\n",
    "    return last_ngames(df[df.SEASON_ID == season_id],ngames,game_date,col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling_cols(df,col_list,ngames,rolling_kind):\n",
    "    if rolling_kind == 'mean':\n",
    "        rolling_func = lambda (a,b,c): pd.rolling_mean(a,b,min_periods = c)\n",
    "    elif rolling_kind == 'sum':\n",
    "        rolling_func = lambda (a,b,c): pd.rolling_sum(a,b,min_periods = c)\n",
    "    else:\n",
    "        return None \n",
    "    \n",
    "    rolling_df = (df.groupby([\"PLAYER_NAME\",\"SEASON_ID\"])\n",
    "                    .apply(lambda x: add_game_date_pts_col(rolling_func((x[col_list],ngames,1)),x.GAME_DATE,x.FANTASY_PTS).reset_index(drop = True)))\n",
    "    return rolling_df.reset_index().drop('level_2',axis = 1).rename(columns=dict(zip(col_list,map(lambda x: 'R_' + x,col_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_game_date_pts_col(df,game_date_col,fantasy_pts_col):\n",
    "    new_df = pd.concat([df,game_date_col], axis = 1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def per_season_cumsum(df,col_list):\n",
    "    cumsum_df = (df.groupby([\"PLAYER_NAME\",\"SEASON_ID\"])\n",
    "                   .apply(lambda x: add_game_date_col(x[col_list].cumsum(axis = 0), x.GAME_DATE).reset_index(drop = True)))\n",
    "    return cumsum_df.reset_index().drop('level_2',axis = 1).rename(columns=dict(zip(col_list,map(lambda x: 'C_' + x,col_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def per_season_cummean(df,col_list):\n",
    "    cumsum_df = (df.groupby([\"PLAYER_NAME\",\"SEASON_ID\"])\n",
    "                   .apply(lambda x: add_game_date_pts_col(pd.expanding_mean(x[col_list], min_periods = 2), x.GAME_DATE, x.FANTASY_PTS).reset_index(drop = True)))\n",
    "    return cumsum_df.reset_index().drop('level_2',axis = 1).rename(columns=dict(zip(col_list,map(lambda x: 'C_' + x,col_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enumerate_games(df):\n",
    "    new_df = df.copy()\n",
    "    new_df[\"GAME_NUM\"] = range(1,len(df.GAME_DATE) + 1)\n",
    "    return new_df\n",
    "\n",
    "def sigmoidfun(x):\n",
    "\treturn 1/(1+np.exp(-0.007*(x-800)))\n",
    "\n",
    "def fantasy_avg_lastn(player_df,last_n_seasons,seasons):\n",
    "    return player_df[[s in seasons[-last_n_seasons:] for s in player_df.SEASON_ID]]['FANTASY_PTS'].mean()    \n",
    "\n",
    "def true_fantasy_mean(player_df,last_n_seasons):\n",
    "    seasons = list(set(player_df.SEASON_ID))\n",
    "    lastn_mean = fantasy_avg_lastn(player_df,last_n_seasons,seasons)\n",
    "    return player_df.groupby(\"SEASON_ID\").apply(lambda x: x.apply(lambda y: lastn_mean + sigmoidfun(y.MIN) * (y.C_FANTASY_PTS - lastn_mean),axis = 1))\n",
    "\n",
    "def fantasy_resp(df):\n",
    "    return df.groupby('PLAYER_NAME').apply(lambda x: true_fantasy_mean(x,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.decomposition import PCA\n",
    "#train_test_split(xrange(df.shape[0]), train_size=0.7)\n",
    "\n",
    "def mape(ypred, ytrue):\n",
    "    \"\"\" returns the mean absolute percentage error \"\"\"\n",
    "    idx = ytrue != 0.0\n",
    "    return 100*np.mean(np.abs(ypred[idx]-ytrue[idx])/ytrue[idx])\n",
    "\n",
    "def run_classifier(df, mask, ewma_colresp,ewma_colfeats):\n",
    "    dftouse = df.copy()\n",
    "\n",
    "    ewma_feats = map(lambda x: 'EWMA_LOG_' + x , ewma_colfeats)\n",
    "    STANDARDIZABLE = ['EWMA_LOG_' + ewma_colresp, 'EWMA_OPP_POS'] + ewma_feats\n",
    "    for col in STANDARDIZABLE:\n",
    "        print col\n",
    "        valstrain=df[col].values[mask]\n",
    "        valstest=df[col].values[~mask]\n",
    "        scaler=StandardScaler().fit(valstrain)\n",
    "        outtrain=scaler.transform(valstrain)\n",
    "        outtest=scaler.fit_transform(valstest)\n",
    "        out=np.empty(mask.shape[0])\n",
    "        out[mask]=outtrain\n",
    "        out[~mask]=outtest\n",
    "        dftouse[col]=out\n",
    "\n",
    "    lcols = STANDARDIZABLE + [\"OKAY\",\"GOOD\",\"GREAT\"]\n",
    "\n",
    "\n",
    "    clfsvm = LR()\n",
    "    #cs=[.0001,.001,.01,.1,1,10]\n",
    "    #n_estimators = [1,2,10,100,500,1000]\n",
    "    #max_depth = [2,3,5,7,10]\n",
    "    #pca = PCA(n_components=5)\n",
    "    feats = list(set(lcols) - set(['OKAY','GOOD','GREAT']))\n",
    "\n",
    "\n",
    "    Xmatrix=dftouse[lcols]#pca.fit_transform(np.array(dftouse[feats]))\n",
    "    Yresp=dftouse[ewma_colresp + '_RESP'].values \n",
    "    Xmatrix_train=Xmatrix[mask]\n",
    "    Xmatrix_test=Xmatrix[~mask]\n",
    "    Yresp_train=Yresp[mask]\n",
    "    Yresp_test=Yresp[~mask]\n",
    "\n",
    "    #your code here\n",
    "    # from sklearn.grid_search import GridSearchCV\n",
    "    # #{'n_estimators':n_estimators,'max_depth':max_depth}\n",
    "    # gs=GridSearchCV(clfsvm, param_grid={'C':cs}, cv=5)\n",
    "    # gs.fit(Xmatrix_train, Yresp_train)\n",
    "    # print \"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_\n",
    "\n",
    "    # #calculate the accuracy here\n",
    "    # best = gs.best_estimator_\n",
    "    # best.fit(Xmatrix_train, Yresp_train)\n",
    "    # best.score(Xmatrix_test, Yresp_test)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    return clfsvm, Xmatrix_train, Yresp_train, Xmatrix_test, Yresp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_player_seasons(player_name, game_date,df,ewma_colresp, ewma_colfeat):\n",
    "    player_df = df[df.PLAYER_NAME == player_name]\n",
    "    player_df2 = pd.concat([player_df.reset_index(drop = True),player_df.groupby(\"SEASON_ID\").apply(lambda x: np.log(pd.ewma(x[ewma_colresp], span = 3).shift(1) + 2.5).reset_index().drop('index',axis=1).rename(columns={ewma_colresp:'EWMA_LOG_' + ewma_colresp})).reset_index(drop = True)],axis = 1)\n",
    "    for ewma_col in ewma_colfeat:\n",
    "        player_df2['EWMA_LOG_' + ewma_col] = player_df2.groupby(\"SEASON_ID\").apply(lambda x: np.log(pd.ewma(x[ewma_col], span = 3).shift(1) + 2.5).reset_index().drop('index',axis=1).rename(columns={ewma_col:'EWMA_LOG_' + ewma_col})).reset_index(drop = True)\n",
    "    #1 if np.log(y[ewma_colresp] + 1) >= y['EWMA_LOG_' + ewma_colresp] else 0\n",
    "    resp = player_df2.groupby('SEASON_ID').apply(lambda x: x.apply(lambda y: np.log(y[ewma_colresp] + 2.5), axis = 1).reset_index().drop('index',axis=1).rename(columns={0: ewma_colresp + '_RESP'})).reset_index(drop = True)\n",
    "    player_df3 = pd.concat([player_df2,resp], axis = 1)\n",
    "    player_df_final = player_df3.dropna()\n",
    "    return player_df_final, np.array(player_df_final.GAME_DATE < game_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_players_by_season_count(df,players):\n",
    "    season_count = lambda x: len(set(df[df.PLAYER_NAME == x].SEASON_ID))\n",
    "    sub_players = filter(lambda x: season_count(x) >= 2, players)\n",
    "    return sub_players\n",
    "\n",
    "def reduce_picks(player_name,game_date, df, ewma_colresp, ewma_colfeats):\n",
    "    seasons = list(set(df[df.PLAYER_NAME == player_name].SEASON_ID))\n",
    "    season1 = seasons[1]\n",
    "    dftouse,mask = get_player_seasons(player_name, game_date, df, ewma_colresp, ewma_colfeats)\n",
    "    clf,xtrain,ytrain,xtest,ytest = run_classifier(dftouse,mask,ewma_colresp, ewma_colfeats)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    print player_name\n",
    "    print 'The error is %0.2f%%' % mape(clf.predict(xtest),ytest)\n",
    "    dfreturn = dftouse[~mask].copy()\n",
    "    dfreturn['PRED' + ewma_colresp] = clf.predict(xtest)\n",
    "    return dfreturn\n",
    "\n",
    "def min_season(df,players):\n",
    "    season = sorted(map(lambda x: df[df.PLAYER_NAME == x].SEASON_ID.min(),players))[0]\n",
    "    return season\n",
    "\n",
    "def make_ewma_pos_df(df, game_date):\n",
    "    game_day_df = df[(df.GAME_DATE == game_date)]\n",
    "    sub_df = df[(df.GAME_DATE <= game_date)]\n",
    "    potential_players = list(set(game_day_df.PLAYER_NAME))\n",
    "    players = filter_players_by_season_count(sub_df[['PLAYER_NAME','SEASON_ID']],potential_players)\n",
    "    lower_bound = min_season(sub_df[['PLAYER_NAME','SEASON_ID']],players)\n",
    "    sub_df2 = sub_df[sub_df.SEASON_ID >= lower_bound]\n",
    "    ewma_pos = sub_df2.groupby([\"OPP\",'SEASON_ID',\"POSITION\",\"GAME_DATE\"]).apply(lambda x: x.FANTASY_PTS.sum())\n",
    "    \n",
    "    ewma_pos_df_temp = (ewma_pos.reset_index().rename(columns={0:'TOT_OPP_POS'})\n",
    "                                .sort_values('GAME_DATE')\n",
    "                                .groupby([\"OPP\",'SEASON_ID',\"POSITION\"])\n",
    "                                .apply(lambda x: \n",
    "                                    pd.DataFrame(zip(x.GAME_DATE,[-5 if np.isinf(y) else y for y in np.log(pd.ewma(x.TOT_OPP_POS, span = 3).shift(1) + 2.5)]), \n",
    "                                    index = range(x.shape[0])))\n",
    "                                .rename(columns={0:'GAME_DATE',1:'EWMA_OPP_POS'})\n",
    "                                .reset_index(level = [0,1,2]))\n",
    "    merge_on = ['OPP','GAME_DATE','POSITION','SEASON_ID']\n",
    "    ewma_pos_df = pd.merge(sub_df2,ewma_pos_df_temp,left_on=merge_on, right_on=merge_on)\n",
    "    league_avg_df = (ewma_pos_df.groupby([\"SEASON_ID\",'POSITION'])\n",
    "                     .apply(lambda x: x['EWMA_OPP_POS'].mean())\n",
    "                     .reset_index()\n",
    "                     .rename(columns={0:'LEAGUE_AVG_POS'}))\n",
    "    nan_dict = dict(reduce(lambda x,y: x + y.items(),[{(k1,k2):v} for k1,k2,v in league_avg_df.to_records(index = False)], []))\n",
    "    nan_rows = pd.isnull(ewma_pos_df['EWMA_OPP_POS'])\n",
    "    ewma_pos_df.loc[nan_rows,'EWMA_OPP_POS'] = ewma_pos_df[nan_rows].apply(lambda x: nan_dict[x.SEASON_ID - 1,x.POSITION] if x.SEASON_ID > lower_bound else float('nan'), axis = 1)\n",
    "    return ewma_pos_df, players\n",
    "\n",
    "def classify_players_ondate(df,players, game_date,ewma_colresp, ewma_colfeats):\n",
    "    store_df = []\n",
    "    for player in players:\n",
    "        print player\n",
    "        store_df.append(reduce_picks(player,game_date, df, ewma_colresp, ewma_colfeats))\n",
    "    return pd.concat(store_df, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_player_pool(df,game_date,ewma_colresp, ewma_colfeats):\n",
    "    ewma_pos_df, players = make_ewma_pos_df(df, game_date)\n",
    "    return classify_players_ondate(ewma_pos_df, players,game_date,ewma_colresp,ewma_colfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CM_HEIGHT(x):\n",
    "    MELO_HT = x['HEIGHT'] * 4.5\n",
    "    return 'MELO_HT',MELO_HT\n",
    "\n",
    "def CM_WEIGHT(x):\n",
    "    MELO_WT = x['WEIGHT'] * 2.0\n",
    "    return 'MELO_WT',MELO_WT\n",
    "\n",
    "def CM_CAREER_MINUTES(x):\n",
    "    MELO_CAREER_MIN = x['SEASON_MIN'] * 2.5\n",
    "    return 'MELO_CAREER_MIN', MELO_CAREER_MIN\n",
    "\n",
    "def CM_AGE(x):\n",
    "    MELO_AGE = x['AGE']\n",
    "    return 'MELO_AGE', MELO_AGE\n",
    "\n",
    "def CM_MIN_PER(x):\n",
    "    MIN_PER = x['MIN'] * 4.5\n",
    "    return 'MELO_MIN_PER',MIN_PER\n",
    "\n",
    "def CM_MIN_TOT(x):\n",
    "    MIN_TOT = (x['MIN'] * x['GP']) * 7\n",
    "    return 'MELO_MIN_TOT', MIN_TOT\n",
    "\n",
    "def CM_TRUE_PER(x):\n",
    "    TRUE_PER = x['TS_PCT'] * 6\n",
    "    return 'MELO_TRUE_PER',TRUE_PER\n",
    "\n",
    "def CM_USG_PER(x):\n",
    "    USG_PER = x['USG_PCT'] * 6\n",
    "    return 'MELO_USG_PER',USG_PER\n",
    "\n",
    "def CM_AST_PER(x):\n",
    "    AST_PER = x['AST_PCT'] * 5\n",
    "    return 'MELO_AST_PCT', AST_PER\n",
    "\n",
    "def CM_TO_PER(x):\n",
    "    TO_PER= x['TM_TOV_PCT'] * 2.5\n",
    "    return 'MELO_TO_PCT', TO_PER\n",
    "\n",
    "def CM_REB_PER(x):\n",
    "    REB_PER = x['REB_PCT'] * 5\n",
    "    return 'MELO_REB_PCT', REB_PER\n",
    "\n",
    "def CM_OFF_PM(x):\n",
    "    OFF_PM= x['OFF_RATING'] * 3\n",
    "    return 'OFF_PM', OFF_PM\n",
    "\n",
    "def CM_DF_PM(x):\n",
    "    DEF_PM= x['DEF_RATING'] * 3\n",
    "    return 'DEF_PM', DEF_PM\n",
    "\n",
    "def CM_3FEQ(x):\n",
    "    MELO_3FEQ = x['3PT_FEQ'] * 3.5\n",
    "    return 'MELO_3FEQ',MELO_3FEQ\n",
    "\n",
    "def CM_FT_PER(x):\n",
    "    MELO_FT_PER = x['FT_PER'] * 3.5\n",
    "    return 'MELO_FT_PER',MELO_FT_PER\n",
    "\n",
    "def weight_prop(cat_str, weight_dict):\n",
    "    tot = sum(weight_dict.values())\n",
    "    prop = weight_dict[cat_str] / tot\n",
    "    return prop\n",
    "\n",
    "def make_melo_sim(fab_std,cat_str):\n",
    "    fab_std_player_idx = fab_std.set_index('PLAYER_NAME')\n",
    "    fab_comp = pd.DataFrame(index=fab_std_player_idx.index.tolist(), columns=fab_std_player_idx.index.tolist())\n",
    "    prop = weight_prop(cat_str, weights)\n",
    "    melo_category = (fab_comp.apply(lambda x: fab_comp.columns,axis = 1)\n",
    "             .apply(lambda x: fab_std_player_idx.loc[x.name][cat_str] - fab_std_player_idx.loc[x][cat_str], axis = 1)\n",
    "             .applymap(lambda x: x**2 * prop))\n",
    "    return melo_category\n",
    "\n",
    "def fab_melo(player, comboMELO):\n",
    "    root = comboMELO[comboMELO.PLAYER_NAME == player].sort_values('PLAYER_NAME')\n",
    "    calc_melo_funcs = [CM_WEIGHT, CM_HEIGHT, CM_MIN_PER,CM_CAREER_MINUTES, CM_3FEQ, CM_MIN_TOT, CM_TRUE_PER, CM_USG_PER, CM_AST_PER, CM_TO_PER, CM_REB_PER, CM_OFF_PM, CM_DF_PM,CM_FT_PER,CM_AGE]\n",
    "    result = root.groupby('SEASON_ID').apply(lambda x: pd.DataFrame(dict([('SEASON_ID',x.SEASON_ID),('PLAYER_NAME',x.PLAYER_NAME)] + map(lambda y: y(x),calc_melo_funcs))))\n",
    "    return result\n",
    "\n",
    "def zscore(col):\n",
    "    return (col - col.mean())/col.std(ddof=0)\n",
    "    \n",
    "store_df = []\n",
    "melo_advanced_df = pd.read_csv(\"./usage_stats/comboMELO.csv\") \n",
    "players = set(season_subset(df85_15,1996,2015)['PLAYER_NAME'])\n",
    "for player in players:\n",
    "    store_df.append(fab_melo(player,melo_advanced_df))\n",
    "FAB_MELO = pd.concat(store_df,axis = 0)\n",
    "melo_cols = [\"MELO_MIN_PER\", \"MELO_MIN_TOT\", \"DEF_PM\",\"OFF_PM\", \"MELO_AST_PCT\", \"MELO_REB_PCT\", \"MELO_TO_PCT\",\"MELO_USG_PER\", \"MELO_TRUE_PER\",\"MELO_3FEQ\",\"MELO_FT_PER\",\"MELO_CAREER_MIN\",\"MELO_WT\",\"MELO_HT\"]\n",
    "weights = dict(zip(melo_cols,[4.5,7.0,3.0,3.0,5.0,5.0,2.5,6.0,6.0,3.5,3.5,2.5,2,4.5]))\n",
    "FAB_MELO[melo_cols] = FAB_MELO[melo_cols].apply(zscore, axis =0)\n",
    "get_top_ten(FAB_MELO[FAB_MELO.AGE == 26],weights,\"Danny Green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_df2 = []\n",
    "for i in range(6):\n",
    "    store_df2.append(pd.read_csv('./DKSalaries/DKSalaries' + str(i) + '.csv'))\n",
    "salary_df = pd.concat(store_df,axis = 0)\n",
    "opt_players = list(set(salary_df.Name))\n",
    "sampled_salary = salary_df.groupby(\"Name\").apply(lambda x: x.sample(n=1)).reset_index(drop = True)\n",
    "salary_dict = dict(zip(sampled_salary.Name, sampled_salary.Salary))\n",
    "salary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gafantasypts = singleday['FANTASY_PTS'].values\n",
    "gaforwards = singleday['REAL_POSITION'].map(lambda x: 1 if x == 'Forward' else 0).values\n",
    "gaguards = singleday['REAL_POSITION'].map(lambda x: 1 if x == 'Guard' else 0).values\n",
    "gacenters = singleday['REAL_POSITION'].map(lambda x: 1 if x == 'Center' else 0).values\n",
    "#gautil = np.ones(len(gacenters))\n",
    "gasalaries = singleday['PLAYER_NAME'].map(lambda x: salary_dict[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_data = zip(gasalaries, gafantasypts, gaforwards, gaguards, gacenters)#,gautil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyeasyga import pyeasyga\n",
    "\n",
    "ga = pyeasyga.GeneticAlgorithm(small_data)        # initialise the GA with data\n",
    "ga.population_size = 200000\n",
    "#ga.mutation_probability = 0.05\n",
    "#ga.generations = 25\n",
    "\n",
    "# define a fitness function\n",
    "def fitness(individual, data):\n",
    "    salaries, points, forwards, guards, centers = 0, 0, 0, 0, 0\n",
    "    for (selected, item) in zip(individual, data):\n",
    "        if selected:\n",
    "            salaries += item[0]\n",
    "            points += item[1]\n",
    "            forwards += item[2]\n",
    "            guards += item[3]\n",
    "            centers += item[4]\n",
    "    if salaries > 50000 or ((forwards > 4) and (guards > 4)) or ((guards > 4) and (centers > 2)) or ((forwards > 4) and (centers > 2)) or ((centers + gaurds + forwards) > 8):\n",
    "        points = 0\n",
    "    return points\n",
    "\n",
    "ga.fitness_function = fitness               # set the GA's fitness function\n",
    "ga.run()                                    # run the GA\n",
    "print ga.best_individual()                  # print the GA's best solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_,mask = ga.best_individual()\n",
    "mask = np.array(mask) == 1\n",
    "singleday[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareTimeSeriesCV(X_train, y_train, number_folds):\n",
    "    k = int(np.floor(float(X_train.shape[0]) / number_folds))\n",
    "    \n",
    "    accuracies = np.zeros(number_folds-1)\n",
    "    X_trainFolds, y_trainFolds, X_testFolds, y_testFolds = [], [], [], []\n",
    "    \n",
    "    for i in range(2, number_folds + 1):\n",
    "        split = float(i-1)/i\n",
    "        \n",
    "        X = X_train[:(k*i)]\n",
    "        y = y_train[:(k*i)]\n",
    "        \n",
    "        index = int(np.floor(X.shape[0] * split))\n",
    "        \n",
    "        X_trainFolds.append(X[:index])      \n",
    "        y_trainFolds.append(y[:index])\n",
    "        \n",
    "        X_testFolds.append(X[(index + 1):])\n",
    "        y_testFolds.append(y[(index + 1):])\n",
    "\n",
    "    return X_trainFolds, y_trainFolds, X_testFolds, y_testFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xmatrix_train=Xmatrix[mask]\n",
    "Yresp_train=Yresp[mask]\n",
    "X_train = Xmatrix_train\n",
    "y_train = Yresp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainFolds, y_trainFolds, X_testFolds, y_testFolds = prepareTimeSeriesCV(X_train, y_train, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "from sklearn.svm import LinearSVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#GridSearchCV, authored by David DiCiurcio\n",
    "def davidsearchcv(X_trainFolds, y_trainFolds, X_testFolds, y_testFolds, parameters, classifier):    \n",
    "    templist = []\n",
    "    paramlist = []\n",
    "    outputs = {}\n",
    "    clflist = []\n",
    "    \n",
    "    for i in parameters:\n",
    "        templist.append(parameters[i])\n",
    "    zlist = list(itertools.product(*templist))\n",
    "\n",
    "    for i in zlist:\n",
    "        paramlist.append(dict(zip(parameters.keys(),i)))\n",
    "\n",
    "    counter = 0\n",
    "    for i in paramlist:\n",
    "        stringexec = ''\n",
    "        for k in i:\n",
    "            stringexec = stringexec+k+\"=\"+str(i[k])+\",\"\n",
    "        exec \"clf = \"+classifier+\"(\"+stringexec[:-1]+\")\"\n",
    "        averageaccuracy = []\n",
    "        for j in range(0,len(X_trainFolds)):\n",
    "            clf.fit(X_trainFolds[j], y_trainFolds[j])\n",
    "            averageaccuracy.append(clf.score(X_testFolds[j], y_testFolds[j]))\n",
    "            clflist.append(clf)\n",
    "        outputs[counter] = np.mean(averageaccuracy)\n",
    "        counter = counter + 1\n",
    "    accmaxindex = max(outputs.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    return clflist, paramlist, accmaxindex, outputs[accmaxindex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [0.01, 0.1, 1., 10., 100.]\n",
    "y = [500, 1000, 2000, 4000]\n",
    "z = [5, 10, 20, 50]\n",
    "parameters1={'C':x, 'max_iter':y}\n",
    "parameters={'n_estimators':z}\n",
    "#clflist, vala, valb, valc = davidsearchcv(X_trainFolds, y_trainFolds, X_testFolds, y_testFolds, parameters,'ExtraTreesClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How to perform cross-validation and davidsearchcv\n",
    "X_trainFolds, y_trainFolds, X_testFolds, y_testFolds = prepareTimeSeriesCV(X_train, y_train, 7)\n",
    "clflist, vala, valb, valc = davidsearchcv(X_trainFolds, y_trainFolds, X_testFolds, y_testFolds, parameters,'ExtraTreesClassifier')\n",
    "clflist1, vala1, valb1, valc1 = davidsearchcv(X_trainFolds, y_trainFolds, X_testFolds, y_testFolds, parameters1,'LinearSVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define list of parameters and range of parameters\n",
    "searchlist = [(parameters,'ExtraTreesClassifier'),(parameters1,'LinearSVC')]\n",
    "VCclfLst = []\n",
    "for i in searchlist:\n",
    "    clflist,_,accmaxindex,_ = davidsearchcv(X_trainFolds, y_trainFolds, X_testFolds, y_testFolds,i[0],i[1])\n",
    "    VCclfLst.append((i[1],clflist[accmaxindex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VCclflst = []\n",
    "VCclflst.append(('ETC',clflist[valb]))\n",
    "VCclflst.append(('LSVC',clflist1[valb1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# clflist in form of ('lr', clf1)\n",
    "# weightlist in form of [1, 2, 4]\n",
    "# voting in form of 'soft' or 'hard'\n",
    "def runVotingClassifier(Xtrain,ytrain,Xtest,ytest,clflist,weights,voting):\n",
    "    vcaverage = []\n",
    "    for i in range(0,len(Xtrain)):\n",
    "        eclf = VotingClassifier(estimators=clflist,voting=voting,weights=weights)\n",
    "        eclf.fit(Xtrain[i], ytrain[i])\n",
    "        vcaverage.append(eclf.score(Xtest[i], ytest[i]))\n",
    "    return np.mean(vcaverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runVotingClassifier(X_trainFolds, y_trainFolds, X_testFolds, y_testFolds,VCclfLst,[1,1],'hard')\n",
    "np.ones(len(searchlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClassifierComp(Xtrain, ytrain, kfolds, searchlst,weights,voting):\n",
    "    X_trainFolds, y_trainFolds, X_testFolds, y_testFolds = prepareTimeSeriesCV(Xtrain, ytrain, kfolds)\n",
    "    VCclfLst = []\n",
    "    for i in searchlist:\n",
    "        clflist,_,accmaxindex,_ = davidsearchcv(X_trainFolds, y_trainFolds, X_testFolds, y_testFolds,i[0],i[1])\n",
    "        VCclfLst.append((i[1],clflist[accmaxindex]))\n",
    "    return runVotingClassifier(X_trainFolds, y_trainFolds, X_testFolds, y_testFolds,VCclfLst,weights,voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ClassifierComp(X_train, y_train, 10, searchlist,[1,1],'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ewma_colfeats =['PTS','AST']\n",
    "df,mask = get_player_seasons(\"Kobe Bryant\",2005,2006,ewma_pos_df,ewma_colresp,ewma_colfeats)\n",
    "\n",
    "Xmatrix=df[lcols].values\n",
    "Yresp=df[ewma_colresp + '_RESP'].values \n",
    "Xmatrix_train=Xmatrix[mask]\n",
    "Yresp_train=Yresp[mask]\n",
    "X_train = Xmatrix_train\n",
    "y_train = Yresp_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
